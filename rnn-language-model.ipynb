{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a language model with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wikitext-2\n",
    "The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.\n",
    "\n",
    "The data can be dowloaded here.\n",
    "`https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/yinterian/wikitext-2/wiki.train.tokens'),\n",
       " PosixPath('/data/yinterian/wikitext-2/wiki.valid.tokens'),\n",
       " PosixPath('/data/yinterian/wikitext-2/wiki.test.tokens'),\n",
       " PosixPath('/data/yinterian/wikitext-2/mode117.pth')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=Path(\"/data/yinterian/wikitext-2\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"UNK\": 0}\n",
    "        self.idx2word = [\"UNK\"]\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path, ):\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "        self.train = self.tokenize(os.path.join(path, 'wiki.train.tokens'), add=True)\n",
    "        self.valid = self.tokenize(os.path.join(path, 'wiki.valid.tokens'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'wiki.test.tokens'))\n",
    "        \n",
    "    def count_words(self, path, add=False):\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                if add:\n",
    "                    for word in words:\n",
    "                        self.dictionary.add_word(word)\n",
    "        return tokens\n",
    "\n",
    "    def tokenize(self, path, add=False):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        tokens = self.count_words(path, add)\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r') as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx.get(word, 0)\n",
    "                    token += 1\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Corpus(PATH)\n",
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UNK': 0,\n",
       " '<eos>': 1,\n",
       " '=': 2,\n",
       " 'Valkyria': 3,\n",
       " 'Chronicles': 4,\n",
       " 'III': 5,\n",
       " 'Senjō': 6,\n",
       " 'no': 7,\n",
       " '3': 8,\n",
       " ':': 9,\n",
       " '<unk>': 10,\n",
       " '(': 11,\n",
       " 'Japanese': 12,\n",
       " '戦場のヴァルキュリア3': 13,\n",
       " ',': 14,\n",
       " 'lit': 15,\n",
       " '.': 16,\n",
       " 'of': 17,\n",
       " 'the': 18,\n",
       " 'Battlefield': 19,\n",
       " ')': 20,\n",
       " 'commonly': 21,\n",
       " 'referred': 22,\n",
       " 'to': 23,\n",
       " 'as': 24,\n",
       " 'outside': 25,\n",
       " 'Japan': 26,\n",
       " 'is': 27,\n",
       " 'a': 28,\n",
       " 'tactical': 29,\n",
       " 'role': 30,\n",
       " '@-@': 31,\n",
       " 'playing': 32,\n",
       " 'video': 33,\n",
       " 'game': 34,\n",
       " 'developed': 35,\n",
       " 'by': 36,\n",
       " 'Sega': 37,\n",
       " 'and': 38,\n",
       " 'Media.Vision': 39,\n",
       " 'for': 40,\n",
       " 'PlayStation': 41,\n",
       " 'Portable': 42,\n",
       " 'Released': 43,\n",
       " 'in': 44,\n",
       " 'January': 45,\n",
       " '2011': 46,\n",
       " 'it': 47,\n",
       " 'third': 48,\n",
       " 'series': 49,\n",
       " 'same': 50,\n",
       " 'fusion': 51,\n",
       " 'real': 52,\n",
       " 'time': 53,\n",
       " 'gameplay': 54,\n",
       " 'its': 55,\n",
       " 'predecessors': 56,\n",
       " 'story': 57,\n",
       " 'runs': 58,\n",
       " 'parallel': 59,\n",
       " 'first': 60,\n",
       " 'follows': 61,\n",
       " '\"': 62,\n",
       " 'Nameless': 63,\n",
       " 'penal': 64,\n",
       " 'military': 65,\n",
       " 'unit': 66,\n",
       " 'serving': 67,\n",
       " 'nation': 68,\n",
       " 'Gallia': 69,\n",
       " 'during': 70,\n",
       " 'Second': 71,\n",
       " 'Europan': 72,\n",
       " 'War': 73,\n",
       " 'who': 74,\n",
       " 'perform': 75,\n",
       " 'secret': 76,\n",
       " 'black': 77,\n",
       " 'operations': 78,\n",
       " 'are': 79,\n",
       " 'pitted': 80,\n",
       " 'against': 81,\n",
       " 'Imperial': 82,\n",
       " 'Raven': 83,\n",
       " 'The': 84,\n",
       " 'began': 85,\n",
       " 'development': 86,\n",
       " '2010': 87,\n",
       " 'carrying': 88,\n",
       " 'over': 89,\n",
       " 'large': 90,\n",
       " 'portion': 91,\n",
       " 'work': 92,\n",
       " 'done': 93,\n",
       " 'on': 94,\n",
       " 'II': 95,\n",
       " 'While': 96,\n",
       " 'retained': 97,\n",
       " 'standard': 98,\n",
       " 'features': 99,\n",
       " 'also': 100,\n",
       " 'underwent': 101,\n",
       " 'multiple': 102,\n",
       " 'adjustments': 103,\n",
       " 'such': 104,\n",
       " 'making': 105,\n",
       " 'more': 106,\n",
       " 'newcomers': 107,\n",
       " 'Character': 108,\n",
       " 'designer': 109,\n",
       " 'Honjou': 110,\n",
       " 'composer': 111,\n",
       " 'Hitoshi': 112,\n",
       " 'Sakimoto': 113,\n",
       " 'both': 114,\n",
       " 'returned': 115,\n",
       " 'from': 116,\n",
       " 'previous': 117,\n",
       " 'entries': 118,\n",
       " 'along': 119,\n",
       " 'with': 120,\n",
       " 'director': 121,\n",
       " 'Takeshi': 122,\n",
       " 'Ozawa': 123,\n",
       " 'A': 124,\n",
       " 'team': 125,\n",
       " 'writers': 126,\n",
       " 'handled': 127,\n",
       " 'script': 128,\n",
       " \"'s\": 129,\n",
       " 'opening': 130,\n",
       " 'theme': 131,\n",
       " 'was': 132,\n",
       " 'sung': 133,\n",
       " 'May': 134,\n",
       " \"'n\": 135,\n",
       " 'It': 136,\n",
       " 'met': 137,\n",
       " 'positive': 138,\n",
       " 'sales': 139,\n",
       " 'praised': 140,\n",
       " 'western': 141,\n",
       " 'critics': 142,\n",
       " 'After': 143,\n",
       " 'release': 144,\n",
       " 'received': 145,\n",
       " 'downloadable': 146,\n",
       " 'content': 147,\n",
       " 'an': 148,\n",
       " 'expanded': 149,\n",
       " 'edition': 150,\n",
       " 'November': 151,\n",
       " 'that': 152,\n",
       " 'year': 153,\n",
       " 'adapted': 154,\n",
       " 'into': 155,\n",
       " 'manga': 156,\n",
       " 'original': 157,\n",
       " 'animation': 158,\n",
       " 'Due': 159,\n",
       " 'low': 160,\n",
       " 'not': 161,\n",
       " 'localized': 162,\n",
       " 'but': 163,\n",
       " 'fan': 164,\n",
       " 'translation': 165,\n",
       " 'compatible': 166,\n",
       " 'released': 167,\n",
       " '2014': 168,\n",
       " 'would': 169,\n",
       " 'return': 170,\n",
       " 'franchise': 171,\n",
       " 'Azure': 172,\n",
       " 'Revolution': 173,\n",
       " '4': 174,\n",
       " 'Gameplay': 175,\n",
       " 'As': 176,\n",
       " 'games': 177,\n",
       " 'where': 178,\n",
       " 'players': 179,\n",
       " 'take': 180,\n",
       " 'control': 181,\n",
       " 'part': 182,\n",
       " 'missions': 183,\n",
       " 'enemy': 184,\n",
       " 'forces': 185,\n",
       " 'Stories': 186,\n",
       " 'told': 187,\n",
       " 'through': 188,\n",
       " 'comic': 189,\n",
       " 'book': 190,\n",
       " 'like': 191,\n",
       " 'panels': 192,\n",
       " 'animated': 193,\n",
       " 'character': 194,\n",
       " 'portraits': 195,\n",
       " 'characters': 196,\n",
       " 'speaking': 197,\n",
       " 'partially': 198,\n",
       " 'voiced': 199,\n",
       " 'speech': 200,\n",
       " 'bubbles': 201,\n",
       " 'text': 202,\n",
       " 'player': 203,\n",
       " 'progresses': 204,\n",
       " 'linear': 205,\n",
       " 'gradually': 206,\n",
       " 'unlocked': 207,\n",
       " 'maps': 208,\n",
       " 'can': 209,\n",
       " 'be': 210,\n",
       " 'freely': 211,\n",
       " 'replayed': 212,\n",
       " 'they': 213,\n",
       " 'route': 214,\n",
       " 'each': 215,\n",
       " 'location': 216,\n",
       " 'map': 217,\n",
       " 'varies': 218,\n",
       " 'depending': 219,\n",
       " 'individual': 220,\n",
       " 'approach': 221,\n",
       " 'when': 222,\n",
       " 'one': 223,\n",
       " 'option': 224,\n",
       " 'selected': 225,\n",
       " 'other': 226,\n",
       " 'sealed': 227,\n",
       " 'off': 228,\n",
       " 'Outside': 229,\n",
       " 'rest': 230,\n",
       " 'camp': 231,\n",
       " 'units': 232,\n",
       " 'customized': 233,\n",
       " 'growth': 234,\n",
       " 'occurs': 235,\n",
       " 'Alongside': 236,\n",
       " 'main': 237,\n",
       " 'specific': 238,\n",
       " 'sub': 239,\n",
       " 'relating': 240,\n",
       " 'different': 241,\n",
       " 'squad': 242,\n",
       " 'members': 243,\n",
       " 'completion': 244,\n",
       " 'additional': 245,\n",
       " 'episodes': 246,\n",
       " 'some': 247,\n",
       " 'them': 248,\n",
       " 'having': 249,\n",
       " 'higher': 250,\n",
       " 'difficulty': 251,\n",
       " 'than': 252,\n",
       " 'those': 253,\n",
       " 'found': 254,\n",
       " 'There': 255,\n",
       " 'love': 256,\n",
       " 'simulation': 257,\n",
       " 'elements': 258,\n",
       " 'related': 259,\n",
       " 'two': 260,\n",
       " 'although': 261,\n",
       " 'very': 262,\n",
       " 'minor': 263,\n",
       " 'battle': 264,\n",
       " 'system': 265,\n",
       " 'carried': 266,\n",
       " 'directly': 267,\n",
       " 'During': 268,\n",
       " 'select': 269,\n",
       " 'using': 270,\n",
       " 'top': 271,\n",
       " 'down': 272,\n",
       " 'perspective': 273,\n",
       " 'battlefield': 274,\n",
       " 'once': 275,\n",
       " 'moves': 276,\n",
       " 'around': 277,\n",
       " 'person': 278,\n",
       " 'only': 279,\n",
       " 'act': 280,\n",
       " 'per': 281,\n",
       " 'turn': 282,\n",
       " 'granted': 283,\n",
       " 'turns': 284,\n",
       " 'at': 285,\n",
       " 'expense': 286,\n",
       " \"'\": 287,\n",
       " 'Each': 288,\n",
       " 'has': 289,\n",
       " 'field': 290,\n",
       " 'distance': 291,\n",
       " 'movement': 292,\n",
       " 'limited': 293,\n",
       " 'their': 294,\n",
       " 'Action': 295,\n",
       " 'Up': 296,\n",
       " 'nine': 297,\n",
       " 'assigned': 298,\n",
       " 'single': 299,\n",
       " 'mission': 300,\n",
       " 'will': 301,\n",
       " 'call': 302,\n",
       " 'out': 303,\n",
       " 'if': 304,\n",
       " 'something': 305,\n",
       " 'happens': 306,\n",
       " 'health': 307,\n",
       " 'points': 308,\n",
       " 'HP': 309,\n",
       " 'getting': 310,\n",
       " 'or': 311,\n",
       " 'being': 312,\n",
       " 'knocked': 313,\n",
       " 'attacks': 314,\n",
       " 'Potentials': 315,\n",
       " 'skills': 316,\n",
       " 'unique': 317,\n",
       " 'They': 318,\n",
       " 'divided': 319,\n",
       " 'Personal': 320,\n",
       " 'Potential': 321,\n",
       " 'which': 322,\n",
       " 'innate': 323,\n",
       " 'remain': 324,\n",
       " 'unaltered': 325,\n",
       " 'unless': 326,\n",
       " 'otherwise': 327,\n",
       " 'dictated': 328,\n",
       " 'either': 329,\n",
       " 'help': 330,\n",
       " 'impede': 331,\n",
       " 'Battle': 332,\n",
       " 'grown': 333,\n",
       " 'throughout': 334,\n",
       " 'always': 335,\n",
       " 'grant': 336,\n",
       " 'To': 337,\n",
       " 'learn': 338,\n",
       " 'Masters': 339,\n",
       " 'Table': 340,\n",
       " 'grid': 341,\n",
       " 'based': 342,\n",
       " 'skill': 343,\n",
       " 'table': 344,\n",
       " 'used': 345,\n",
       " 'acquire': 346,\n",
       " 'link': 347,\n",
       " 'Characters': 348,\n",
       " 'have': 349,\n",
       " 'Special': 350,\n",
       " 'temporary': 351,\n",
       " 'Kurt': 352,\n",
       " 'activate': 353,\n",
       " 'Direct': 354,\n",
       " 'Command': 355,\n",
       " 'move': 356,\n",
       " 'without': 357,\n",
       " 'his': 358,\n",
       " 'Point': 359,\n",
       " 'gauge': 360,\n",
       " 'shift': 361,\n",
       " 'her': 362,\n",
       " 'Form': 363,\n",
       " 'become': 364,\n",
       " 'while': 365,\n",
       " 'Imca': 366,\n",
       " 'target': 367,\n",
       " 'heavy': 368,\n",
       " 'weapon': 369,\n",
       " 'Troops': 370,\n",
       " 'five': 371,\n",
       " 'classes': 372,\n",
       " 'Scouts': 373,\n",
       " 'Engineers': 374,\n",
       " 'Armored': 375,\n",
       " 'Soldier': 376,\n",
       " 'switch': 377,\n",
       " 'changing': 378,\n",
       " 'Changing': 379,\n",
       " 'class': 380,\n",
       " 'does': 381,\n",
       " 'greatly': 382,\n",
       " 'affect': 383,\n",
       " 'stats': 384,\n",
       " 'gained': 385,\n",
       " 'With': 386,\n",
       " 'victory': 387,\n",
       " 'experience': 388,\n",
       " 'awarded': 389,\n",
       " 'distributed': 390,\n",
       " 'attributes': 391,\n",
       " 'shared': 392,\n",
       " 'entire': 393,\n",
       " 'feature': 394,\n",
       " 'differing': 395,\n",
       " 'early': 396,\n",
       " 'method': 397,\n",
       " 'distributing': 398,\n",
       " 'types': 399,\n",
       " 'Plot': 400,\n",
       " 'takes': 401,\n",
       " 'place': 402,\n",
       " 'Gallian': 403,\n",
       " 'Army': 404,\n",
       " 'Squad': 405,\n",
       " '422': 406,\n",
       " 'known': 407,\n",
       " 'composed': 408,\n",
       " 'criminals': 409,\n",
       " 'foreign': 410,\n",
       " 'offenders': 411,\n",
       " 'whose': 412,\n",
       " 'names': 413,\n",
       " 'erased': 414,\n",
       " 'records': 415,\n",
       " 'officially': 416,\n",
       " 'numbers': 417,\n",
       " 'most': 418,\n",
       " 'dangerous': 419,\n",
       " 'Regular': 420,\n",
       " 'Militia': 421,\n",
       " 'do': 422,\n",
       " 'nevertheless': 423,\n",
       " 'up': 424,\n",
       " 'task': 425,\n",
       " 'exemplified': 426,\n",
       " 'motto': 427,\n",
       " 'meaning': 428,\n",
       " 'Always': 429,\n",
       " 'Ready': 430,\n",
       " 'three': 431,\n",
       " 'Irving': 432,\n",
       " 'army': 433,\n",
       " 'officer': 434,\n",
       " 'falsely': 435,\n",
       " 'accused': 436,\n",
       " 'treason': 437,\n",
       " 'wishes': 438,\n",
       " 'redeem': 439,\n",
       " 'himself': 440,\n",
       " ';': 441,\n",
       " 'Ace': 442,\n",
       " 'female': 443,\n",
       " 'Darcsen': 444,\n",
       " 'weapons': 445,\n",
       " 'specialist': 446,\n",
       " 'seeks': 447,\n",
       " 'revenge': 448,\n",
       " 'destroyed': 449,\n",
       " 'home': 450,\n",
       " 'Riela': 451,\n",
       " 'seemingly': 452,\n",
       " 'young': 453,\n",
       " 'woman': 454,\n",
       " 'unknowingly': 455,\n",
       " 'descendant': 456,\n",
       " 'Together': 457,\n",
       " 'fellow': 458,\n",
       " 'these': 459,\n",
       " 'tasked': 460,\n",
       " 'fight': 461,\n",
       " 'mysterious': 462,\n",
       " 'Calamity': 463,\n",
       " 'consisting': 464,\n",
       " 'mostly': 465,\n",
       " 'soldiers': 466,\n",
       " 'exist': 467,\n",
       " 'upper': 468,\n",
       " 'echelons': 469,\n",
       " 'exploit': 470,\n",
       " 'concept': 471,\n",
       " 'plausible': 472,\n",
       " 'order': 473,\n",
       " 'send': 474,\n",
       " 'make': 475,\n",
       " 'lose': 476,\n",
       " 'face': 477,\n",
       " 'war': 478,\n",
       " 'times': 479,\n",
       " 'this': 480,\n",
       " 'works': 481,\n",
       " 'advantage': 482,\n",
       " 'successful': 483,\n",
       " 'incursion': 484,\n",
       " 'territory': 485,\n",
       " 'orders': 486,\n",
       " 'cause': 487,\n",
       " 'certain': 488,\n",
       " '422nd': 489,\n",
       " 'great': 490,\n",
       " 'distress': 491,\n",
       " 'One': 492,\n",
       " 'member': 493,\n",
       " 'becomes': 494,\n",
       " 'so': 495,\n",
       " 'enraged': 496,\n",
       " 'he': 497,\n",
       " 'abandons': 498,\n",
       " 'post': 499,\n",
       " 'defects': 500,\n",
       " 'ranks': 501,\n",
       " 'attached': 502,\n",
       " 'ideal': 503,\n",
       " 'independence': 504,\n",
       " 'proposed': 505,\n",
       " 'leader': 506,\n",
       " 'Dahau': 507,\n",
       " 'At': 508,\n",
       " 'within': 509,\n",
       " 'erase': 510,\n",
       " 'protect': 511,\n",
       " 'own': 512,\n",
       " 'interests': 513,\n",
       " 'allies': 514,\n",
       " 'enemies': 515,\n",
       " 'combined': 516,\n",
       " 'presence': 517,\n",
       " 'traitor': 518,\n",
       " 'desperately': 519,\n",
       " 'keep': 520,\n",
       " 'themselves': 521,\n",
       " 'alive': 522,\n",
       " 'effort': 523,\n",
       " 'This': 524,\n",
       " 'continues': 525,\n",
       " 'until': 526,\n",
       " 'commanding': 527,\n",
       " 'Ramsey': 528,\n",
       " 'Crowe': 529,\n",
       " 'had': 530,\n",
       " 'been': 531,\n",
       " 'kept': 532,\n",
       " 'under': 533,\n",
       " 'house': 534,\n",
       " 'arrest': 535,\n",
       " 'escorted': 536,\n",
       " 'capital': 537,\n",
       " 'city': 538,\n",
       " 'present': 539,\n",
       " 'evidence': 540,\n",
       " 'weary': 541,\n",
       " 'expose': 542,\n",
       " 'General': 543,\n",
       " 'Treason': 544,\n",
       " 'due': 545,\n",
       " 'events': 546,\n",
       " 'partly': 547,\n",
       " 'major': 548,\n",
       " 'losses': 549,\n",
       " 'manpower': 550,\n",
       " 'suffers': 551,\n",
       " 'towards': 552,\n",
       " 'end': 553,\n",
       " 'Empire': 554,\n",
       " 'offered': 555,\n",
       " 'formal': 556,\n",
       " 'position': 557,\n",
       " 'rather': 558,\n",
       " 'serve': 559,\n",
       " 'anonymous': 560,\n",
       " 'shadow': 561,\n",
       " 'force': 562,\n",
       " 'short': 563,\n",
       " 'lived': 564,\n",
       " 'however': 565,\n",
       " 'following': 566,\n",
       " 'Maximilian': 567,\n",
       " 'defeat': 568,\n",
       " 'ancient': 569,\n",
       " 'super': 570,\n",
       " 'benefactor': 571,\n",
       " 'Without': 572,\n",
       " 'support': 573,\n",
       " 'chance': 574,\n",
       " 'prove': 575,\n",
       " 'last': 576,\n",
       " 'card': 577,\n",
       " 'creating': 578,\n",
       " 'new': 579,\n",
       " 'armed': 580,\n",
       " 'invading': 581,\n",
       " 'just': 582,\n",
       " 'nations': 583,\n",
       " 'cease': 584,\n",
       " 'fire': 585,\n",
       " 'certainly': 586,\n",
       " 'wreck': 587,\n",
       " 'newfound': 588,\n",
       " 'peace': 589,\n",
       " 'decides': 590,\n",
       " 'again': 591,\n",
       " 'asking': 592,\n",
       " 'list': 593,\n",
       " 'all': 594,\n",
       " 'command': 595,\n",
       " 'killed': 596,\n",
       " 'action': 597,\n",
       " 'Now': 598,\n",
       " 'owing': 599,\n",
       " 'allegiance': 600,\n",
       " 'none': 601,\n",
       " 'confronts': 602,\n",
       " 'destroys': 603,\n",
       " 'then': 604,\n",
       " 'goes': 605,\n",
       " 'separate': 606,\n",
       " 'ways': 607,\n",
       " 'begin': 608,\n",
       " 'lives': 609,\n",
       " 'Development': 610,\n",
       " 'Concept': 611,\n",
       " 'after': 612,\n",
       " 'finished': 613,\n",
       " 'full': 614,\n",
       " 'beginning': 615,\n",
       " 'shortly': 616,\n",
       " 'took': 617,\n",
       " 'approximately': 618,\n",
       " 'staff': 619,\n",
       " 'look': 620,\n",
       " 'popular': 621,\n",
       " 'response': 622,\n",
       " 'what': 623,\n",
       " 'wanted': 624,\n",
       " 'next': 625,\n",
       " 'Like': 626,\n",
       " 'predecessor': 627,\n",
       " 'wanting': 628,\n",
       " 'refine': 629,\n",
       " 'mechanics': 630,\n",
       " 'created': 631,\n",
       " 'come': 632,\n",
       " 'revolutionary': 633,\n",
       " 'idea': 634,\n",
       " 'warrant': 635,\n",
       " 'entry': 636,\n",
       " 'Speaking': 637,\n",
       " 'interview': 638,\n",
       " 'stated': 639,\n",
       " 'considered': 640,\n",
       " 'true': 641,\n",
       " 'sequel': 642,\n",
       " 'required': 643,\n",
       " 'amount': 644,\n",
       " 'trial': 645,\n",
       " 'error': 646,\n",
       " 'platform': 647,\n",
       " 'gave': 648,\n",
       " 'improve': 649,\n",
       " 'upon': 650,\n",
       " 'best': 651,\n",
       " 'parts': 652,\n",
       " 'In': 653,\n",
       " 'addition': 654,\n",
       " 'scenario': 655,\n",
       " 'written': 656,\n",
       " 'Hiroyuki': 657,\n",
       " 'Its': 658,\n",
       " 'darker': 659,\n",
       " 'somber': 660,\n",
       " 'majority': 661,\n",
       " 'material': 662,\n",
       " 'design': 663,\n",
       " 'improvements': 664,\n",
       " 'were': 665,\n",
       " 'made': 666,\n",
       " 'graphics': 667,\n",
       " 'layouts': 668,\n",
       " 'structure': 669,\n",
       " 'number': 670,\n",
       " 'playable': 671,\n",
       " 'upgrade': 672,\n",
       " 'involved': 673,\n",
       " 'models': 674,\n",
       " 'body': 675,\n",
       " 'achieve': 676,\n",
       " 'cooperative': 677,\n",
       " 'incorporated': 678,\n",
       " 'second': 679,\n",
       " 'removed': 680,\n",
       " 'memory': 681,\n",
       " 'space': 682,\n",
       " 'needed': 683,\n",
       " 'adjusted': 684,\n",
       " 'settings': 685,\n",
       " 'ease': 686,\n",
       " 'play': 687,\n",
       " 'could': 688,\n",
       " 'appeal': 689,\n",
       " 'retaining': 690,\n",
       " 'essential': 691,\n",
       " 'components': 692,\n",
       " 'newer': 693,\n",
       " 'systems': 694,\n",
       " 'decided': 695,\n",
       " 'designs': 696,\n",
       " 'worked': 697,\n",
       " 'When': 698,\n",
       " 'faced': 699,\n",
       " 'problem': 700,\n",
       " 'uniforms': 701,\n",
       " 'essentially': 702,\n",
       " 'individuality': 703,\n",
       " 'despite': 704,\n",
       " 'him': 705,\n",
       " 'needing': 706,\n",
       " 'create': 707,\n",
       " 'identify': 708,\n",
       " 'maintaining': 709,\n",
       " 'sense': 710,\n",
       " 'reality': 711,\n",
       " 'world': 712,\n",
       " 'color': 713,\n",
       " 'engine': 714,\n",
       " 'anime': 715,\n",
       " 'produced': 716,\n",
       " 'Production': 717,\n",
       " 'I.G.': 718,\n",
       " 'Music': 719,\n",
       " 'music': 720,\n",
       " 'originally': 721,\n",
       " 'heard': 722,\n",
       " 'about': 723,\n",
       " 'project': 724,\n",
       " 'thought': 725,\n",
       " 'light': 726,\n",
       " 'tone': 727,\n",
       " 'similar': 728,\n",
       " 'themes': 729,\n",
       " 'much': 730,\n",
       " 'expected': 731,\n",
       " 'An': 732,\n",
       " 'designed': 733,\n",
       " 'vision': 734,\n",
       " 'rejected': 735,\n",
       " 'He': 736,\n",
       " 'seven': 737,\n",
       " 'production': 738,\n",
       " 'need': 739,\n",
       " 'initially': 740,\n",
       " 'recorded': 741,\n",
       " 'orchestra': 742,\n",
       " 'guitar': 743,\n",
       " 'bass': 744,\n",
       " 'synthesizer': 745,\n",
       " 'before': 746,\n",
       " 'segments': 747,\n",
       " 'piece': 748,\n",
       " 'incorporating': 749,\n",
       " 'hopeful': 750,\n",
       " 'tune': 751,\n",
       " 'played': 752,\n",
       " 'ending': 753,\n",
       " 'modern': 754,\n",
       " 'divorced': 755,\n",
       " 'fantasy': 756,\n",
       " 'musical': 757,\n",
       " 'instruments': 758,\n",
       " 'constructed': 759,\n",
       " 'working': 760,\n",
       " 'synthesized': 761,\n",
       " 'felt': 762,\n",
       " 'incorporate': 763,\n",
       " 'live': 764,\n",
       " 'arranged': 765,\n",
       " 'several': 766,\n",
       " 'later': 767,\n",
       " 'tracks': 768,\n",
       " 'song': 769,\n",
       " 'If': 770,\n",
       " 'You': 771,\n",
       " 'Wish': 772,\n",
       " '...': 773,\n",
       " 'Kimi': 774,\n",
       " 'singer': 775,\n",
       " 'reason': 776,\n",
       " 'fought': 777,\n",
       " 'particular': 778,\n",
       " 'wish': 779,\n",
       " 'precious': 780,\n",
       " 'responsibility': 781,\n",
       " 'duty': 782,\n",
       " 'lyrics': 783,\n",
       " 'singles': 784,\n",
       " 'Release': 785,\n",
       " 'September': 786,\n",
       " 'teaser': 787,\n",
       " 'website': 788,\n",
       " 'revealed': 789,\n",
       " 'hinting': 790,\n",
       " 'issue': 791,\n",
       " 'Famitsu': 792,\n",
       " 'listed': 793,\n",
       " 'arriving': 794,\n",
       " 'public': 795,\n",
       " 'appearance': 796,\n",
       " 'Tokyo': 797,\n",
       " 'Game': 798,\n",
       " 'Show': 799,\n",
       " 'TGS': 800,\n",
       " 'demo': 801,\n",
       " 'available': 802,\n",
       " 'journalists': 803,\n",
       " 'attendees': 804,\n",
       " 'publicity': 805,\n",
       " 'details': 806,\n",
       " 'too': 807,\n",
       " 'potential': 808,\n",
       " 'still': 809,\n",
       " 'flux': 810,\n",
       " 'reveal': 811,\n",
       " 'promote': 812,\n",
       " 'detail': 813,\n",
       " 'leading': 814,\n",
       " 'episodic': 815,\n",
       " 'Flash': 816,\n",
       " 'visual': 817,\n",
       " 'novel': 818,\n",
       " '27': 819,\n",
       " 'said': 820,\n",
       " 'capacity': 821,\n",
       " 'DLC': 822,\n",
       " 'plans': 823,\n",
       " 'finalized': 824,\n",
       " 'Multiple': 825,\n",
       " 'featuring': 826,\n",
       " 'between': 827,\n",
       " 'February': 828,\n",
       " 'April': 829,\n",
       " 'Extra': 830,\n",
       " 'Edition': 831,\n",
       " '23': 832,\n",
       " 'sold': 833,\n",
       " 'lower': 834,\n",
       " 'price': 835,\n",
       " 'chosen': 836,\n",
       " 'pre': 837,\n",
       " 'bonus': 838,\n",
       " 'People': 839,\n",
       " 'owned': 840,\n",
       " 'transfer': 841,\n",
       " 'save': 842,\n",
       " 'data': 843,\n",
       " 'versions': 844,\n",
       " 'Unlike': 845,\n",
       " 'west': 846,\n",
       " 'According': 847,\n",
       " 'poor': 848,\n",
       " 'general': 849,\n",
       " 'unpopularity': 850,\n",
       " 'PSP': 851,\n",
       " 'unofficial': 852,\n",
       " 'patch': 853,\n",
       " '2012': 854,\n",
       " 'copy': 855,\n",
       " 'download': 856,\n",
       " 'apply': 857,\n",
       " 'translated': 858,\n",
       " 'English': 859,\n",
       " 'Reception': 860,\n",
       " 'On': 861,\n",
       " 'day': 862,\n",
       " 'topped': 863,\n",
       " 'exclusive': 864,\n",
       " 'multi': 865,\n",
       " 'charts': 866,\n",
       " 'By': 867,\n",
       " '102': 868,\n",
       " '@,@': 869,\n",
       " 'coming': 870,\n",
       " 'overall': 871,\n",
       " 'Last': 872,\n",
       " 'Story': 873,\n",
       " 'Wii': 874,\n",
       " '152': 875,\n",
       " '500': 876,\n",
       " 'enjoyed': 877,\n",
       " 'particularly': 878,\n",
       " 'pleased': 879,\n",
       " 'gaming': 880,\n",
       " 'site': 881,\n",
       " 'Watch': 882,\n",
       " 'negatively': 883,\n",
       " 'noting': 884,\n",
       " 'pacing': 885,\n",
       " 'recycled': 886,\n",
       " 'generally': 887,\n",
       " 'entertaining': 888,\n",
       " 'putting': 889,\n",
       " 'spikes': 890,\n",
       " 'writer': 891,\n",
       " 'Play': 892,\n",
       " 'Test': 893,\n",
       " 'article': 894,\n",
       " 'provided': 895,\n",
       " 'profound': 896,\n",
       " 'feeling': 897,\n",
       " 'closure': 898,\n",
       " 'annoying': 899,\n",
       " 'limitations': 900,\n",
       " 'aspects': 901,\n",
       " 'special': 902,\n",
       " 'abilities': 903,\n",
       " 'positively': 904,\n",
       " 'noted': 905,\n",
       " 'Official': 906,\n",
       " 'Magazine': 907,\n",
       " '-': 908,\n",
       " 'UK': 909,\n",
       " 'moral': 910,\n",
       " 'standing': 911,\n",
       " 'art': 912,\n",
       " 'style': 913,\n",
       " 'latter': 914,\n",
       " 'continued': 915,\n",
       " 'quality': 916,\n",
       " 'tweaks': 917,\n",
       " 'balance': 918,\n",
       " 'criticism': 919,\n",
       " 'affected': 920,\n",
       " 'Heath': 921,\n",
       " 'Hindman': 922,\n",
       " 'non': 923,\n",
       " 'removal': 924,\n",
       " 'praising': 925,\n",
       " 'returning': 926,\n",
       " 'serious': 927,\n",
       " 'Points': 928,\n",
       " 'criticized': 929,\n",
       " 'review': 930,\n",
       " 'awkward': 931,\n",
       " 'cutscenes': 932,\n",
       " 'seemed': 933,\n",
       " 'include': 934,\n",
       " 'scene': 935,\n",
       " 'good': 936,\n",
       " 'issues': 937,\n",
       " 'occasional': 938,\n",
       " 'problems': 939,\n",
       " 'AI': 940,\n",
       " 'preview': 941,\n",
       " 'Ryan': 942,\n",
       " 'Geddes': 943,\n",
       " 'IGN': 944,\n",
       " 'left': 945,\n",
       " 'excited': 946,\n",
       " 'go': 947,\n",
       " 'completing': 948,\n",
       " 'enjoying': 949,\n",
       " 'improved': 950,\n",
       " 'visuals': 951,\n",
       " 'Kotaku': 952,\n",
       " 'Richard': 953,\n",
       " 'highly': 954,\n",
       " 'citing': 955,\n",
       " 'form': 956,\n",
       " 'His': 957,\n",
       " 'criticisms': 958,\n",
       " 'length': 959,\n",
       " 'repetition': 960,\n",
       " 'expressing': 961,\n",
       " 'regret': 962,\n",
       " 'Legacy': 963,\n",
       " 'featured': 964,\n",
       " 'Nintendo': 965,\n",
       " '3DS': 966,\n",
       " 'crossover': 967,\n",
       " 'Project': 968,\n",
       " 'X': 969,\n",
       " 'Zone': 970,\n",
       " 'representing': 971,\n",
       " 'develop': 972,\n",
       " 'forms': 973,\n",
       " 'Adaptations': 974,\n",
       " 'episode': 975,\n",
       " 'Taken': 976,\n",
       " 'Sake': 977,\n",
       " 'Network': 978,\n",
       " 'planned': 979,\n",
       " 'availability': 980,\n",
       " 'period': 981,\n",
       " 'extended': 982,\n",
       " 'stoppage': 983,\n",
       " 'summer': 984,\n",
       " 'DVD': 985,\n",
       " 'June': 986,\n",
       " '29': 987,\n",
       " 'August': 988,\n",
       " '31': 989,\n",
       " 'Black': 990,\n",
       " 'Blue': 991,\n",
       " 'editions': 992,\n",
       " 'purchase': 993,\n",
       " 'set': 994,\n",
       " 'half': 995,\n",
       " 'detailing': 996,\n",
       " 'rivals': 997,\n",
       " 'announced': 998,\n",
       " '1': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dictionary.word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_data = batchify(corpus.train, batch_size)\n",
    "val_data = batchify(corpus.valid, batch_size)\n",
    "test_data = batchify(corpus.test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104431"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Based on the model [here](https://github.com/pytorch/examples/tree/master/word_language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.rnn = nn.GRU(ninp, nhid, nlayers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        self.init_weights()\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.fill_(0.0)\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return Variable(weight.new(self.nlayers, bsz, self.nhid).zero_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, bptt, evaluation=False):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 20]) torch.Size([700])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(train_data, 0, 35)\n",
    "print(x.data.shape, y.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "      1\n",
       "    285\n",
       "  15179\n",
       "    281\n",
       "    349\n",
       "    129\n",
       "    290\n",
       "   9494\n",
       "     17\n",
       "      2\n",
       "     14\n",
       "      1\n",
       "   2702\n",
       "   1228\n",
       "   1564\n",
       "   4045\n",
       "    116\n",
       "   1353\n",
       "   1336\n",
       "     17\n",
       " [torch.cuda.LongTensor of size 20 (GPU 0)], Variable containing:\n",
       "  2\n",
       " [torch.cuda.LongTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:], y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify2(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.LongTensor(list(range(2005)))\n",
    "d = batchify2(data, 20)\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, bptt, evaluation=False):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 20])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_batch(d, i=0, bptt=15)\n",
    "x.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_data, lr_low=1e-3, lr_high=10, epochs=2):\n",
    "    losses = []\n",
    "    (train_data.size(0) - 1)//bptt + 1\n",
    "    iterations = epochs * ((train_data.size(0) - 1)//bptt + 1)\n",
    "    delta = (lr_high - lr_low)/(iterations-1)\n",
    "    losses = []\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    total_loss = 0\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    for i in range(epochs):\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "            lr = lrs[ind]\n",
    "            data, targets = get_batch(train_data, i, bptt)\n",
    "        \n",
    "            hidden = Variable(hidden.data) #.detach()\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = criterion(output.view(-1, ntokens), targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "            for p in model.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "            losses.append(loss.data[0])\n",
    "            ind += 1\n",
    "    return lrs, losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemb = 300\n",
    "nhid = 300\n",
    "nlayers = 2\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = RNNModel(ntokens, nemb, nhid, nlayers).cuda()\n",
    "lrs, losses = LR_range_finder(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5968"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triangular_lr2(lr_low, lr_high, iterations):\n",
    "    iter1 = int(0.35*iterations)\n",
    "    iter2 = int(0.85*iter1)\n",
    "    iter3 = iterations - iter1 - iter2\n",
    "    delta1 = (lr_high - lr_low)/iter1\n",
    "    delta2 = (lr_high - lr_low)/(iter1 -1)\n",
    "    lrs1 = [lr_low + i*delta1 for i in range(iter1)]\n",
    "    lrs2 = [lr_high - i*(delta1) for i in range(0, iter2)]\n",
    "    delta2 = (lrs2[-1] - lr_low)/(iter3)\n",
    "    lrs3 = [lrs2[-1] - i*(delta2) for i in range(1, iter3+1)]\n",
    "    return lrs1+lrs2+lrs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for i in range(0, data_source.size(0) - 1, bptt):\n",
    "        data, targets = get_batch(data_source, i, bptt, evaluation=True)\n",
    "        output, hidden = model(data, hidden)\n",
    "        output_flat = output.view(-1, ntokens)\n",
    "        total_loss += len(data) * criterion(output_flat, targets).data\n",
    "        hidden = Variable(hidden.data) #.detach()\n",
    "    return total_loss[0] / len(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "    return Variable(h.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "bptt = 35\n",
    "clip = 0.25\n",
    "\n",
    "def get_batch(source, i, bptt, evaluation=False):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
    "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
    "    return data, target\n",
    "    \n",
    "def train_triangular_policy(model, epochs=4, lr_low=1e-4, lr_high=4):\n",
    "    # Turn on training mode which enables dropout.\n",
    "    start_time = time.time()\n",
    "    ntokens = len(corpus.dictionary)\n",
    "    iterations = epochs * ((train_data.size(0) - 1)//bptt + 1)\n",
    "    lrs = get_triangular_lr2(lr_low, lr_high, iterations)\n",
    "    idx = 0\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "            lr = lrs[idx]\n",
    "            data, targets = get_batch(train_data, i, bptt)\n",
    "            # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "            # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "            hidden = Variable(hidden.data) #.detach()\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = criterion(output.view(-1, ntokens), targets)\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
    "            for p in model.parameters():\n",
    "                p.data.add_(-lr, p.grad.data)\n",
    "\n",
    "            total_loss += len(data)*loss.data\n",
    "            idx += 1\n",
    "        # results after each epoch\n",
    "        val_loss = evaluate(val_data)\n",
    "        elapsed = time.time() - start_time\n",
    "        train_loss = total_loss[0]/len(train_data)\n",
    "        print('| epoch {:3d} | lr {:02.5f} | t_loss {:5.2f} | t_ppl {:5.2f} | v_loss {:5.2f} | v_ppl {:5.2f}'.format(\n",
    "             epoch, lr, train_loss, math.exp(train_loss), val_loss, math.exp(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "nemb = 300\n",
    "nhid = 300\n",
    "nlayers = 2\n",
    "ntokens = len(corpus.dictionary)\n",
    "model = RNNModel(ntokens, nemb, nhid, nlayers).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33279"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 8.28489 | t_loss  6.52 | t_ppl 676.54 | v_loss  5.88 | v_ppl 356.71\n",
      "| epoch   1 | lr 7.42878 | t_loss  5.81 | t_ppl 334.17 | v_loss  5.46 | v_ppl 234.26\n",
      "| epoch   2 | lr 4.63954 | t_loss  5.47 | t_ppl 237.65 | v_loss  5.29 | v_ppl 198.54\n",
      "| epoch   3 | lr 4.00000 | t_loss  5.30 | t_ppl 200.86 | v_loss  5.21 | v_ppl 182.89\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=4, lr_high=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 8.28489 | t_loss  5.23 | t_ppl 186.70 | v_loss  5.25 | v_ppl 191.28\n",
      "| epoch   1 | lr 7.42878 | t_loss  5.21 | t_ppl 183.43 | v_loss  5.15 | v_ppl 173.28\n",
      "| epoch   2 | lr 4.63954 | t_loss  5.05 | t_ppl 155.99 | v_loss  5.05 | v_ppl 156.07\n",
      "| epoch   3 | lr 4.00000 | t_loss  4.95 | t_ppl 141.00 | v_loss  5.01 | v_ppl 150.53\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=4, lr_high=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 6.28489 | t_loss  4.89 | t_ppl 133.02 | v_loss  5.03 | v_ppl 152.95\n",
      "| epoch   1 | lr 5.42878 | t_loss  4.92 | t_ppl 137.17 | v_loss  5.01 | v_ppl 150.15\n",
      "| epoch   2 | lr 2.63954 | t_loss  4.81 | t_ppl 122.90 | v_loss  4.95 | v_ppl 140.68\n",
      "| epoch   3 | lr 2.00000 | t_loss  4.75 | t_ppl 115.03 | v_loss  4.92 | v_ppl 136.56\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=2, lr_high=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 4.57074 | t_loss  4.72 | t_ppl 111.86 | v_loss  4.96 | v_ppl 142.24\n",
      "| epoch   1 | lr 3.85731 | t_loss  4.75 | t_ppl 116.10 | v_loss  4.93 | v_ppl 138.41\n",
      "| epoch   2 | lr 1.53295 | t_loss  4.68 | t_ppl 107.77 | v_loss  4.89 | v_ppl 132.51\n",
      "| epoch   3 | lr 1.00000 | t_loss  4.64 | t_ppl 103.22 | v_loss  4.88 | v_ppl 131.12\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=1, lr_high=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 4.57074 | t_loss  4.63 | t_ppl 102.69 | v_loss  4.94 | v_ppl 139.68\n",
      "| epoch   1 | lr 3.85731 | t_loss  4.68 | t_ppl 107.69 | v_loss  4.91 | v_ppl 135.64\n",
      "| epoch   2 | lr 1.53295 | t_loss  4.61 | t_ppl 100.48 | v_loss  4.88 | v_ppl 131.01\n",
      "| epoch   3 | lr 1.00000 | t_loss  4.57 | t_ppl 96.27 | v_loss  4.86 | v_ppl 128.77\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=1, lr_high=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 4.57074 | t_loss  4.57 | t_ppl 96.16 | v_loss  4.94 | v_ppl 139.16\n",
      "| epoch   1 | lr 3.85731 | t_loss  4.62 | t_ppl 101.75 | v_loss  4.90 | v_ppl 134.75\n",
      "| epoch   2 | lr 1.53295 | t_loss  4.55 | t_ppl 94.81 | v_loss  4.87 | v_ppl 130.20\n",
      "| epoch   3 | lr 1.00000 | t_loss  4.51 | t_ppl 90.76 | v_loss  4.84 | v_ppl 126.99\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=1, lr_high=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 2.99952 | t_loss  4.50 | t_ppl 89.72 | v_loss  4.87 | v_ppl 130.73\n",
      "| epoch   1 | lr 2.50012 | t_loss  4.53 | t_ppl 92.41 | v_loss  4.87 | v_ppl 130.96\n",
      "| epoch   2 | lr 0.87306 | t_loss  4.48 | t_ppl 88.63 | v_loss  4.85 | v_ppl 127.19\n",
      "| epoch   3 | lr 0.50000 | t_loss  4.46 | t_ppl 86.83 | v_loss  4.83 | v_ppl 124.72\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=0.5, lr_high=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 2.85945 | t_loss  4.46 | t_ppl 86.33 | v_loss  4.88 | v_ppl 131.15\n",
      "| epoch   1 | lr 2.29014 | t_loss  4.49 | t_ppl 89.12 | v_loss  4.86 | v_ppl 129.46\n",
      "| epoch   2 | lr 0.43529 | t_loss  4.46 | t_ppl 86.08 | v_loss  4.81 | v_ppl 122.88\n",
      "| epoch   3 | lr 0.01000 | t_loss  4.47 | t_ppl 86.95 | v_loss  4.77 | v_ppl 118.41\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=0.01, lr_high=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 2.14531 | t_loss  4.43 | t_ppl 83.85 | v_loss  4.86 | v_ppl 129.56\n",
      "| epoch   1 | lr 1.71867 | t_loss  4.45 | t_ppl 85.22 | v_loss  4.86 | v_ppl 128.80\n",
      "| epoch   2 | lr 0.32870 | t_loss  4.43 | t_ppl 83.67 | v_loss  4.81 | v_ppl 122.69\n",
      "| epoch   3 | lr 0.01000 | t_loss  4.44 | t_ppl 85.17 | v_loss  4.77 | v_ppl 117.78\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=0.01, lr_high=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | lr 1.42858 | t_loss  4.41 | t_ppl 82.25 | v_loss  4.84 | v_ppl 126.83\n",
      "| epoch   1 | lr 1.14335 | t_loss  4.41 | t_ppl 82.16 | v_loss  4.83 | v_ppl 125.69\n",
      "| epoch   2 | lr 0.21407 | t_loss  4.41 | t_ppl 81.95 | v_loss  4.79 | v_ppl 120.86\n",
      "| epoch   3 | lr 0.00100 | t_loss  4.44 | t_ppl 84.46 | v_loss  4.77 | v_ppl 117.45\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, epochs=4, lr_low=0.001, lr_high=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p):\n",
    "    torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p):\n",
    "    m.load_state_dict(torch.load(p))\n",
    "\n",
    "p = PATH/\"mode117.pth\"\n",
    "save_model(model, str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/yinterian/wikitext-2/mode117.pth\n"
     ]
    }
   ],
   "source": [
    "p = PATH/\"mode117.pth\"\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://github.com/pytorch/examples/tree/master/word_language_model\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
